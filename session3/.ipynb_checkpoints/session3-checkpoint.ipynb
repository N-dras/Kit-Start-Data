{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données\n",
    "\n",
    "- trouver/supprimer les données dupliquées : df.duplicated() / df.drop_duplicates()\n",
    "- renommer des colonnes : df.rename(columns={...))\n",
    "- trouver les NaN : df.isnull() / df.notnull() / df.dropna()\n",
    "- travail sur les chaines : series.str.extract(), series.str.contains(), series.get_dummies()\n",
    "- mapping : series.map()\n",
    "- changer le type d'une série (cast) : df.astype(type) / pd.to_numeric() / pd.to_datetime()\n",
    "- remplacer n'importe quelle valeur : df.replace({...})\n",
    "- remplacer les NaN : df.fillna(), series.combine_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement et analyse des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email address</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>money</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>phone</th>\n",
       "      <th>registration</th>\n",
       "      <th>inactive</th>\n",
       "      <th>last_seen</th>\n",
       "      <th>address</th>\n",
       "      <th>preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27625</td>\n",
       "      <td>Leandra</td>\n",
       "      <td>Pabelik</td>\n",
       "      <td>lpabelik5f@yale.edu</td>\n",
       "      <td>Female</td>\n",
       "      <td>63</td>\n",
       "      <td>$55.18</td>\n",
       "      <td>18.284100</td>\n",
       "      <td>49.632552</td>\n",
       "      <td>0136319724</td>\n",
       "      <td>2019/04/16</td>\n",
       "      <td>False</td>\n",
       "      <td>1.559566e+09</td>\n",
       "      <td>Palkovice, Czech Republic</td>\n",
       "      <td>entrée/plat/dessert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27570</td>\n",
       "      <td>Ruthi</td>\n",
       "      <td>Ross</td>\n",
       "      <td>rross3w@sohu.com</td>\n",
       "      <td>Female</td>\n",
       "      <td>57</td>\n",
       "      <td>$20.37</td>\n",
       "      <td>19.230220</td>\n",
       "      <td>50.466575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018/10/23</td>\n",
       "      <td>False</td>\n",
       "      <td>1.567165e+09</td>\n",
       "      <td>Siewierz, Poland</td>\n",
       "      <td>entrée/plat/dessert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27572</td>\n",
       "      <td>Silas</td>\n",
       "      <td>Stourton</td>\n",
       "      <td>silas.stourton3y@answers.com</td>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>€32,99</td>\n",
       "      <td>118.831081</td>\n",
       "      <td>24.984813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018/12/30</td>\n",
       "      <td>False</td>\n",
       "      <td>1.553692e+09</td>\n",
       "      <td>Longbo, China</td>\n",
       "      <td>entrée/plat/dessert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27435</td>\n",
       "      <td>Roxine</td>\n",
       "      <td>Pettecrew</td>\n",
       "      <td>rpettecrew5@gravatar.com</td>\n",
       "      <td>F</td>\n",
       "      <td>64</td>\n",
       "      <td>£98,93</td>\n",
       "      <td>121.648987</td>\n",
       "      <td>-8.844744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019/03/12</td>\n",
       "      <td>False</td>\n",
       "      <td>1.552349e+09</td>\n",
       "      <td>Potulando, Indonesia</td>\n",
       "      <td>entrée/plat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27558</td>\n",
       "      <td>Margaux</td>\n",
       "      <td>Gowanson</td>\n",
       "      <td>nope@thankyou.</td>\n",
       "      <td>Female</td>\n",
       "      <td>54</td>\n",
       "      <td>$13.30</td>\n",
       "      <td>14.772557</td>\n",
       "      <td>45.160472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018/08/13</td>\n",
       "      <td>False</td>\n",
       "      <td>1.543383e+09</td>\n",
       "      <td>Bribir, Croatia</td>\n",
       "      <td>entrée/plat/dessert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>27465</td>\n",
       "      <td>Adelind</td>\n",
       "      <td>Christin</td>\n",
       "      <td>achristinz@blogs.com</td>\n",
       "      <td>Female</td>\n",
       "      <td>30</td>\n",
       "      <td>€81,84</td>\n",
       "      <td>41.427853</td>\n",
       "      <td>52.415968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019/06/04</td>\n",
       "      <td>False</td>\n",
       "      <td>1.559606e+09</td>\n",
       "      <td>Znamenka, Russia</td>\n",
       "      <td>entrée/plat/dessert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>27476</td>\n",
       "      <td>Petronella</td>\n",
       "      <td>Pickance</td>\n",
       "      <td>ppickance1a@uiuc.edu</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>€37.15</td>\n",
       "      <td>132.702111</td>\n",
       "      <td>33.762296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017/11/22</td>\n",
       "      <td>False</td>\n",
       "      <td>1.532870e+09</td>\n",
       "      <td>Iyo, Japan</td>\n",
       "      <td>entrée/plat/dessert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>27521</td>\n",
       "      <td>Moritz</td>\n",
       "      <td>Issacof</td>\n",
       "      <td>missacof2j@wired.com</td>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>$91.97</td>\n",
       "      <td>72.311099</td>\n",
       "      <td>31.263396</td>\n",
       "      <td>0298949280</td>\n",
       "      <td>2018/08/20</td>\n",
       "      <td>False</td>\n",
       "      <td>1.549817e+09</td>\n",
       "      <td>Jhang Sadr, Pakistan</td>\n",
       "      <td>entrée/plat/dessert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>27441</td>\n",
       "      <td>Quintana</td>\n",
       "      <td>Foulstone</td>\n",
       "      <td>qfoulstoneb@newsvine.com</td>\n",
       "      <td>F</td>\n",
       "      <td>32</td>\n",
       "      <td>€55,64</td>\n",
       "      <td>111.138442</td>\n",
       "      <td>-6.783653</td>\n",
       "      <td>0734595126</td>\n",
       "      <td>2018/10/25</td>\n",
       "      <td>False</td>\n",
       "      <td>1.540426e+09</td>\n",
       "      <td>Mantingantengah, Indonesia</td>\n",
       "      <td>entrée/plat/dessert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>27597</td>\n",
       "      <td>Trueman</td>\n",
       "      <td>De Haven</td>\n",
       "      <td>tdehaven4n@goo.gl</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>$81.54</td>\n",
       "      <td>-47.208953</td>\n",
       "      <td>-23.088650</td>\n",
       "      <td>0516973570</td>\n",
       "      <td>2017/06/05</td>\n",
       "      <td>False</td>\n",
       "      <td>1.540441e+09</td>\n",
       "      <td>Indaiatuba, Brazil</td>\n",
       "      <td>entrée/plat/dessert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  first_name  last_name                 email address  gender age  \\\n",
       "0    27625     Leandra    Pabelik           lpabelik5f@yale.edu  Female  63   \n",
       "1    27570       Ruthi       Ross              rross3w@sohu.com  Female  57   \n",
       "2    27572       Silas   Stourton  silas.stourton3y@answers.com    Male  22   \n",
       "3    27435      Roxine  Pettecrew      rpettecrew5@gravatar.com       F  64   \n",
       "4    27558     Margaux   Gowanson                nope@thankyou.  Female  54   \n",
       "..     ...         ...        ...                           ...     ...  ..   \n",
       "204  27465     Adelind   Christin          achristinz@blogs.com  Female  30   \n",
       "205  27476  Petronella   Pickance          ppickance1a@uiuc.edu  Female  28   \n",
       "206  27521      Moritz    Issacof          missacof2j@wired.com    Male  21   \n",
       "207  27441    Quintana  Foulstone      qfoulstoneb@newsvine.com       F  32   \n",
       "208  27597     Trueman   De Haven             tdehaven4n@goo.gl    Male  34   \n",
       "\n",
       "      money         lon        lat       phone registration inactive  \\\n",
       "0    $55.18   18.284100  49.632552  0136319724   2019/04/16    False   \n",
       "1    $20.37   19.230220  50.466575         NaN   2018/10/23    False   \n",
       "2    €32,99  118.831081  24.984813         NaN   2018/12/30    False   \n",
       "3    £98,93  121.648987  -8.844744         NaN   2019/03/12    False   \n",
       "4    $13.30   14.772557  45.160472         NaN   2018/08/13    False   \n",
       "..      ...         ...        ...         ...          ...      ...   \n",
       "204  €81,84   41.427853  52.415968         NaN   2019/06/04    False   \n",
       "205  €37.15  132.702111  33.762296         NaN   2017/11/22    False   \n",
       "206  $91.97   72.311099  31.263396  0298949280   2018/08/20    False   \n",
       "207  €55,64  111.138442  -6.783653  0734595126   2018/10/25    False   \n",
       "208  $81.54  -47.208953 -23.088650  0516973570   2017/06/05    False   \n",
       "\n",
       "        last_seen                     address           preference  \n",
       "0    1.559566e+09   Palkovice, Czech Republic  entrée/plat/dessert  \n",
       "1    1.567165e+09            Siewierz, Poland  entrée/plat/dessert  \n",
       "2    1.553692e+09               Longbo, China  entrée/plat/dessert  \n",
       "3    1.552349e+09        Potulando, Indonesia          entrée/plat  \n",
       "4    1.543383e+09             Bribir, Croatia  entrée/plat/dessert  \n",
       "..            ...                         ...                  ...  \n",
       "204  1.559606e+09            Znamenka, Russia  entrée/plat/dessert  \n",
       "205  1.532870e+09                  Iyo, Japan  entrée/plat/dessert  \n",
       "206  1.549817e+09        Jhang Sadr, Pakistan  entrée/plat/dessert  \n",
       "207  1.540426e+09  Mantingantengah, Indonesia  entrée/plat/dessert  \n",
       "208  1.540441e+09          Indaiatuba, Brazil  entrée/plat/dessert  \n",
       "\n",
       "[209 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('people.csv')\n",
    "df0 = df.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209 entries, 0 to 208\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             209 non-null    int64  \n",
      " 1   first_name     207 non-null    object \n",
      " 2   last_name      207 non-null    object \n",
      " 3   email address  203 non-null    object \n",
      " 4   gender         207 non-null    object \n",
      " 5   age            207 non-null    object \n",
      " 6   money          190 non-null    object \n",
      " 7   lon            207 non-null    float64\n",
      " 8   lat            207 non-null    float64\n",
      " 9   phone          83 non-null     object \n",
      " 10  registration   207 non-null    object \n",
      " 11  inactive       207 non-null    object \n",
      " 12  last_seen      190 non-null    float64\n",
      " 13  address        207 non-null    object \n",
      " 14  preference     207 non-null    object \n",
      "dtypes: float64(3), int64(1), object(11)\n",
      "memory usage: 24.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplications\n",
    "\n",
    "- `duplicated()` : `True` ou `False` selon si une ligne est dupliquée\n",
    "- `drop_duplicates()` : suppression des lignes dupliquées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lignes dupliquées\n",
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toutes les lignes dupliquées\n",
    "df.loc[df.duplicated(keep=False)].sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des lignes dupliquées\n",
    "df = df.drop_duplicates()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc\n",
    "#df.drop_duplicates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renommage de la colonne 'email address'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renommer les colonnes\n",
    "df = df.rename(columns={'email address': 'email'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse des données manquantes\n",
    "\n",
    "`numpy.nan` est utilisé dans **pandas** pour représenter des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not A Number\n",
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# élément super absorbant\n",
    "np.nan + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# élément super absorbant\n",
    "np.sqrt(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# élément super absorbant\n",
    "np.nan == np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# au passage infinis numpy\n",
    "np.NINF, np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inf > 1e100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inf + 1e100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inf == np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inf + np.NINF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inf + np.inf > np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests sur les données manquantes\n",
    "\n",
    "- `isnull()` ou `isna()`\n",
    "- `notnull()` ou `notna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ne fonctionne pas\n",
    "df.loc[df['first_name']==np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chercher les first_name Nan\n",
    "df.loc[df['first_name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sur tout le dataframe\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chercher tous les lignes avec au moins un NaN\n",
    "df.loc[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression de toutes les lignes avec un NaN\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression de toutes les lignes avec un NaN\n",
    "df.dropna().isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supprimer uniquement les lignes dont le first_name NaN \n",
    "df = df.dropna(subset=['first_name'])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajout d'une colonne 'full_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'full_name'  = 'first_name last_name'\n",
    "df['full_name'] = df['first_name'] + ' ' + df['last_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse de la colonne 'address'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse de address\n",
    "df['address'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajout des colonnes 'city' et 'country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul de city et country à partir de address\n",
    "df[['city', 'country']] = df['address'].str.extract('(.*), (.*)')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nunique : modalités par colonne\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping du genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse du gender\n",
    "df['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse du gender\n",
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# traitement du gender\n",
    "mapping = {'Female': 'F', 'Male': 'M', 'F': 'F', 'M': 'M'}\n",
    "df['gender'] = df['gender'].map(mapping)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionnaire incomplet\n",
    "mapping0 = {'Female': 'F', 'Male': 'M'}\n",
    "s = df0['gender'].map(mapping0)\n",
    "df0['gender'].count(), s.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionnaire incomplet\n",
    "s = df0['gender'].apply(lambda x: mapping0.get(x, x))\n",
    "s.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitement du gender, map() avec une Series\n",
    "mapping = pd.Series({'Female': 'F', 'Male': 'M', 'F': 'F', 'M': 'M'})\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitement du gender avec une Series\n",
    "df['gender'] = df['gender'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# au final\n",
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse du genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse gender NaN\n",
    "len(df0.loc[df0['gender'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse prénom avec gender NaN\n",
    "df0.loc[df0['gender'].isnull(), 'first_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse gender\n",
    "df0.loc[df0['gender'].isnull(), 'first_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compléter le genre :\n",
    "\n",
    "1. Autocomplétion avec le fichier people.csv (mais très peu de cas)\n",
    "2. Gender API : https://gender-api.com/fr (simple mais API payante si gros volumes + de 500/mois)\n",
    "3. US SSA baby names : https://www.ssa.gov/oact/babynames/limits.html (\"gratuit\", stats à produire, éventuellement affiner par année de naissance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Fichier people.csv\n",
    "for first_name in df0.loc[df0['gender'].isnull(), 'first_name'].unique():\n",
    "    print(first_name, df0.loc[df0['first_name']==first_name, 'gender'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse de l'âge\n",
    "\n",
    "`pandas.Series.astype()` : types\n",
    "\n",
    "`pandas.to_numeric()` : data avec gestion des erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse de l'âge\n",
    "df.loc[df['age'].str.contains('[^0-9]'), 'age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traitement de l'âge\n",
    "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traitement des dates\n",
    "\n",
    "\n",
    "`pandas.to_datetime()` : data, gestion des formats et des erreurs\n",
    "\n",
    "`pandas.Series.combine_first()` : équivalent à `fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_time = ['registration', 'last_seen']\n",
    "df[cols_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols_time].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion des dates\n",
    "df['registration'] = pd.to_datetime(df['registration'])\n",
    "df['last_seen'] = pd.to_datetime(df['last_seen'], unit='s')\n",
    "# si last_seen est NaN, prendre registration\n",
    "df['last_seen'] = df['last_seen'].fillna(df['registration'])\n",
    "# idem\n",
    "df['last_seen'] = df['last_seen'].combine_first(df['registration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse de currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# échantillon\n",
    "np.random.seed(0)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traitement de 'currency'\n",
    "\n",
    "Produire une nouvelle colonne numérique 'money_eur'.\n",
    "\n",
    "Pour la conversion USD/EUR, on utilise l'API https://api.exchangeratesapi.io/latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API\n",
    "import json\n",
    "\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://open.er-api.com/v6/latest/EUR')\n",
    "rates = json.loads(response.content)\n",
    "rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['money'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['currency'] = df['money'].str[0].map({'€': 'EUR', '$': 'USD'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates['rates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction de la currency\n",
    "df['currency'] = df['money'].str[0].map({'€': 'EUR', '$': 'USD', '£': 'GBP'})\n",
    "df['money_eur'] = df['money'].str[1:].str.replace(',', '.')  # extraction des derniers chars + , => .\n",
    "df['money_eur'] = pd.to_numeric(df['money_eur'])  # conversion en nombre\n",
    "\n",
    "# conversion des monnaies en euros\n",
    "df['money_eur'] = df['money_eur'] / df['currency'].map(rates['rates'])\n",
    "#np.random.seed(0)\n",
    "#df.sample(10)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['money_eur'] = df['money_eur'].apply(lambda x: round(x, 2))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse des emails\n",
    "\n",
    "On va utiliser des regex pour nettoyer les emails mais mieux vaut utiliser une librairie spécialisée. Par exemple, https://github.com/syrusakbary/validate_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# email NaN\n",
    "df['email'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des emails absents\n",
    "df = df.dropna(subset=['email']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emails avec chars non admis\n",
    "df.loc[df['email'].str.contains('[^A-Za-z0-9_\\-%+.@]'), 'email'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des blancs\n",
    "df['email'] = df['email'].str.strip()\n",
    "df.loc[df['email'].str.contains('[^A-Za-z0-9_\\-%+.@]'), 'email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex pour vérifier les domaines\n",
    "df.loc[~df['email'].str.contains('.+@[A-Za-z0-9_\\-.]+\\.[A-Za-z]{2,}')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emails avec noms de domaine invalides\n",
    "df = df.loc[df['email'].str.contains('.+@[A-Za-z0-9_\\-.]+\\.[A-Za-z]{2,}')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emails avec aliases (char +)\n",
    "df.loc[df['email'].str.contains('\\+'), 'email'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction des aliases (char +)\n",
    "tab_email = df['email'].str.extract('([^+]+)(\\+.*)?(@.+)').sort_values(0)\n",
    "tab_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '^...' regex au début"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [abc]\n",
    "# [a-zA-Z]\n",
    "# [^abc] : pas a, b ou c\n",
    "# [^0-9] : pas digit\n",
    "# '<[^>]+>' : tag HTML\n",
    "# '<.+>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caractères parenthèses\n",
    "# \\([0-9]+\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parenthèses non capturante\n",
    "# (?:regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suprresion des aliases (char +)\n",
    "df['email'] = tab_email[0] + tab_email[2]\n",
    "df.sort_values('email')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des emails en double, on conserve la première ligne\n",
    "df = df.drop_duplicates(subset=['email'])\n",
    "df.sort_values('email')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse de la colonne 'preference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse de preference\n",
    "df['preference'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse de preference\n",
    "df['preference'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modalités de preference\n",
    "s = set()\n",
    "df['preference'].apply(lambda x: s.update(x.split('/')))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajour d'un booléen par preference\n",
    "for x in sorted(s):\n",
    "    df[x] = df['preference'].str.contains(x)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autre façon avec get_dummies\n",
    "df['preference'].str.get_dummies(sep='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignation des préférences\n",
    "tab_preference = df['preference'].str.get_dummies(sep='/')\n",
    "df[tab_preference.columns] = tab_preference.astype(bool)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def clean_people(df):\n",
    "    \n",
    "    # suppression des lignes dupliquées\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # renommer les colonnes\n",
    "    df = df.rename(columns={'email address': 'email'})\n",
    "    \n",
    "    # supprimer uniquement les lignes dont le first_name vaut NaN \n",
    "    df = df.dropna(subset=['first_name'])\n",
    "    \n",
    "    # ajout d'une colonne 'full_name'\n",
    "    df['full_name'] = df['first_name'] + ' ' + df['last_name']\n",
    "\n",
    "    # calcul de city et country à partir de address\n",
    "    df[['city', 'country']] = df['address'].str.extract('(.*), (.*)')\n",
    "\n",
    "    # traitement du gender\n",
    "    mapping = {'Female': 'F', 'Male': 'M'}\n",
    "    df['gender'] = df['gender'].map(mapping)\n",
    " \n",
    "    # traitement de l'âge\n",
    "    df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "\n",
    "    # conversion des dates\n",
    "    df['registration'] = pd.to_datetime(df.registration)\n",
    "    df['last_seen'] = pd.to_datetime(df.last_seen, unit='s')\n",
    "    # si last_seen est NaN, prendre registration\n",
    "    df['last_seen'] = df['last_seen'].fillna(df['registration'])\n",
    "\n",
    "    # récupération des taux de change\n",
    "    response = requests.get('https://open.er-api.com/v6/latest/EUR')\n",
    "    rates = json.loads(response.content)\n",
    "\n",
    "    # extraction de la currency\n",
    "    df['currency'] = df['money'].str[0].map({'€': 'EUR', '$': 'USD'})\n",
    "    df['money_eur'] = df['money'].str[1:].str.replace(',', '.')  # extraction des derniers chars + , => .\n",
    "    df['money_eur'] = pd.to_numeric(df['money_eur'])  # conversion en nombre\n",
    "\n",
    "    # conversion des monnaies en euros\n",
    "    rates['rates']['EUR'] = 1.0  # ajour de EUR pour pouvoir utiliser map()\n",
    "    df['money_eur'] = df['money_eur'] * df['currency'].map(rates['rates'])\n",
    "\n",
    "    # suppression des emails absents\n",
    "    df = df.dropna(subset=['email'])\n",
    "\n",
    "    # suppression des blancs\n",
    "    df['email'] = df['email'].str.strip()\n",
    "\n",
    "    # emails avec noms de domaine valides\n",
    "    df = df.loc[df['email'].str.contains('.+@[A-Za-z0-9_\\-.]+\\.[A-Za-z]{2,}')]\n",
    "    \n",
    "    # extraction des aliases (char +)\n",
    "    tab_email = df['email'].str.extract('([^+]+)(\\+.*)?(@.+)').sort_values(0)\n",
    "    # suppression des aliases (char +)\n",
    "    df['email'] = tab_email[0] + tab_email[2]\n",
    "\n",
    "    # suppression des emails en double, on conserve la première ligne\n",
    "    df = df.drop_duplicates(subset=['email'])\n",
    "\n",
    "    # assignation des préférences\n",
    "    tab_preference = df['preference'].str.get_dummies(sep='/')\n",
    "    df[tab_preference.columns] = tab_preference.astype(bool)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('people.csv')\n",
    "print(df.shape)\n",
    "\n",
    "df = clean_people(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**\n",
    "\n",
    "1. Téléchargez le fichier Excel \"FranceTHD_Open_Data_Observatoire_2017_T2.xlsx\" sur le niveau des débits sur les réseaux d'accès à Internet : ADSL, câble, Fibre FttH (T2 2015 - T2 2017) de la page : https://www.data.gouv.fr/fr/datasets/niveau-des-debits-sur-les-reseaux-dacces-a-internet-adsl-cable-fibre-ftth-t2-2015-t2-2017/\n",
    "\n",
    "2. Chargez avec pd.read_excel() dans un DataFrame le dernier onglet \"2017 T2\" en mesurant le temps avec %%time en première instruction de cellule.\n",
    "\n",
    "3. Modifiez le nom des 4 premières colonnes en : 'code INSEE', 'commune', 'département', 'nb locaux' par exemple.\n",
    "\n",
    "4. Sauvegardez le DataFrame avec pd.to_pickle().\n",
    "\n",
    "5. Rechargez le DataFrame à partir du fichier pickle en mesurant le temps avec %%time en première instruction de cellule et comparez.\n",
    "\n",
    "6. Effectuez une opération de sélection sur les communes : par exemple, les communes qui commencent par \"SAINT\".\n",
    "\n",
    "7. Diagnostiquez le message d'erreur.\n",
    "\n",
    "8. Corrigez le DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_excel('FranceTHD_Open_Data_Observatoire_2017_T2.xlsx',\n",
    "               sheet_name=-1,\n",
    "               header=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etudier les multiples options de read_csv\n",
    "\n",
    "En particulier:\n",
    "\n",
    "<pre>\n",
    "pd.read_csv(\n",
    "    <strong>filepath_or_buffer: Union[str, pathlib.Path, IO[~AnyStr]],</strong>\n",
    "    <strong>sep=',',</strong>\n",
    "    delimiter=None,\n",
    "    <strong>header='infer',</strong>\n",
    "    <strong>names=None,</strong>\n",
    "    <strong>index_col=None,</strong>\n",
    "    <strong>usecols=None,</strong>\n",
    "    squeeze=False,\n",
    "    prefix=None,\n",
    "    mangle_dupe_cols=True,\n",
    "    <strong>dtype=None,</strong>\n",
    "    <strong>engine=None,</strong>\n",
    "    <strong>converters=None,</strong>\n",
    "    true_values=None,\n",
    "    false_values=None,\n",
    "    skipinitialspace=False,\n",
    "    <strong>skiprows=None,</strong>\n",
    "    <strong>skipfooter=0,</strong>\n",
    "    <strong>nrows=None,</strong>\n",
    "    <strong>na_values=None,</strong>\n",
    "    <strong>keep_default_na=True,</strong>\n",
    "    na_filter=True,\n",
    "    verbose=False,\n",
    "    skip_blank_lines=True,\n",
    "    <strong>parse_dates=False,</strong>\n",
    "    infer_datetime_format=False,\n",
    "    keep_date_col=False,\n",
    "    date_parser=None,\n",
    "    dayfirst=False,\n",
    "    cache_dates=True,\n",
    "    iterator=False,\n",
    "    <strong>chunksize=None,</strong>\n",
    "    compression='infer',\n",
    "    <strong>thousands=None,</strong>\n",
    "    <strong>decimal: str = '.',</strong>\n",
    "    lineterminator=None,\n",
    "    quotechar='\"',\n",
    "    quoting=0,\n",
    "    doublequote=True,\n",
    "    escapechar=None,\n",
    "    comment=None,\n",
    "    encoding=None,\n",
    "    dialect=None,\n",
    "    error_bad_lines=True,\n",
    "    warn_bad_lines=True,\n",
    "    delim_whitespace=False,\n",
    "    low_memory=True,\n",
    "    memory_map=False,\n",
    "    float_precision=None,\n",
    ")\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse automatique avec pandas_profiling\n",
    "\n",
    "https://github.com/pandas-profiling/pandas-profiling\n",
    "\n",
    "**ATTENTION, il vaut mieux installer `pandas_profiling` dans un nouvel environnement**\n",
    "\n",
    "<pre>\n",
    "conda create --name profiling\n",
    "\n",
    "activate profiling OU conda activate profiling\n",
    "\n",
    "conda install -c conda-forge pandas-profiling\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiling raw people\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "df = pd.read_csv('people.csv')\n",
    "\n",
    "profile = ProfileReport(df, title='Pandas Profiling Report', explorative=True)\n",
    "\n",
    "profile.to_file(\"people.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiling clean people\n",
    "profile = ProfileReport(clean_people(df), title='Pandas Profiling Report', explorative=True)\n",
    "\n",
    "profile.to_file(\"clean_people.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
